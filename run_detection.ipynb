{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "def timestamp_to_framestamp(t, fps):\n",
    "    return np.round(np.multiply(t, fps)).astype(int)\n",
    "\n",
    "def framestamp_to_timestamp(f, fps):\n",
    "    return np.divide(f, fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_video(input_video_path, output_video_path, x, y, w, h):\n",
    "    # Open the input video\n",
    "    cap = cv.VideoCapture(input_video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    # Get video properties\n",
    "    fourcc = cv.VideoWriter_fourcc(*'mp4v')\n",
    "    fps = cap.get(cv.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    out = cv.VideoWriter(output_video_path, fourcc, fps, (w, h))\n",
    "\n",
    "    # Process each frame\n",
    "    for i in tqdm(range(frame_count)):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Crop the frame\n",
    "        cropped_frame = frame[y:y+h, x:x+w]\n",
    "\n",
    "        # Write the cropped frame to the output video\n",
    "        out.write(cropped_frame)\n",
    "\n",
    "    # Release everything when job is finished\n",
    "    cap.release()\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Scoring Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_framestamps(input_video_path, basket_bound_x=(115, 160), basket_bound_y=(110, 115), cooldown_seconds=1):\n",
    "    \"\"\"\n",
    "    Records a frame as a score if the ball enters the specified basket bounding box.\n",
    "    The score bounding box should be aligned to the top of the basket.\n",
    "\n",
    "    params:\n",
    "        input_video_path: \n",
    "        output_video_path: \n",
    "        basket_bound_x: tuple\n",
    "        basket_bound_y: tuple\n",
    "        cooldown_seconds: length of time before the next detection is allowed\n",
    "    \"\"\"\n",
    "    line_colour = (227, 73, 121)\n",
    "\n",
    "    # Open the input video\n",
    "    cap = cv.VideoCapture(input_video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    # Get video properties\n",
    "    fps = cap.get(cv.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # removes the background using KNN algorithm, which is good if small parts of a complex background change frequently\n",
    "    # https://www.reddit.com/r/opencv/comments/yrbl07/question_how_does_knn_background_subtractor_work/\n",
    "    # https://en.wikipedia.org/wiki/Kernel_density_estimation \n",
    "    # tl;dr learns a background model by progressively applying each frame to the model\n",
    "    fgbg = cv.createBackgroundSubtractorKNN()\n",
    "\n",
    "    prev_seconds = -1\n",
    "    framestamps = []\n",
    "    # Process each frame\n",
    "    for i in tqdm(range(frame_count)):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # remove background\n",
    "        mask = fgbg.apply(frame)\n",
    "        # median blur to denoise https://docs.opencv.org/4.x/d4/d13/tutorial_py_filtering.html\n",
    "        mask = cv.medianBlur(mask, 5)\n",
    "\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "\n",
    "        # calc ball's center of mass using pixels\n",
    "        com = (np.mean(np.argwhere(mask), axis=0)).astype(int)\n",
    "        cv.circle(frame, com[::-1], 3, line_colour, 2)\n",
    "\n",
    "        cv.line(frame, (basket_bound_x[0], basket_bound_y[0]), (basket_bound_x[1], basket_bound_y[0]), line_colour, 2)\n",
    "        # if com crosses the line, print timestamp\n",
    "        if basket_bound_y[0] < com[0] < basket_bound_y[1] and basket_bound_x[0] < com[1] < basket_bound_x[1]:\n",
    "            current_seconds = i / fps\n",
    "            if not framestamps or current_seconds >= prev_seconds + cooldown_seconds:\n",
    "                print(f\"basket made at: {current_seconds//60:.0f}m{current_seconds%60:.0f}s\")\n",
    "                prev_seconds = current_seconds\n",
    "                framestamps.append(i)\n",
    "\n",
    "    # Release everything when job is finished\n",
    "    cap.release()\n",
    "\n",
    "    print(\"Found \", len(framestamps), \" scored baskets.\")\n",
    "    return framestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Highlight segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def segment_video(input_video_path, score_framestamps, before_score_seconds=3, after_score_seconds=1, split_segments=False):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        input_video_path: path to video to segment; output highlight reel\n",
    "        score_framestamps: list of frames where a basket was scored\n",
    "        before_score_seconds: buffer length before the shot\n",
    "        highlight_len_after_frames: buffer length after the shot\n",
    "        split_segments: whether each segment should be its own video\n",
    "    \"\"\"\n",
    "    # Open the input video\n",
    "    cap = cv.VideoCapture(input_video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    # Get video properties\n",
    "    fourcc = cv.VideoWriter_fourcc(*'mp4v')\n",
    "    fps = cap.get(cv.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "    original_width = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "    original_height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    highlight_frames = before_score_seconds * fps\n",
    "    highlight_num = 0\n",
    "    out = cv.VideoWriter(f\"{Path(input_video_path).stem}_highlight.mp4\", fourcc, fps, (original_width, original_height))\n",
    "    for i in tqdm(range(frame_count)):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if highlight_num == len(score_framestamps):\n",
    "            break\n",
    "\n",
    "        start_frame = max(0, score_framestamps[highlight_num] - highlight_frames) # no negative frame numbers\n",
    "        if i > start_frame:\n",
    "            # if reached end of highlight, move on to next highlight\n",
    "            if i > start_frame + highlight_frames + after_score_seconds*fps:\n",
    "                print(f\"highlight {highlight_num} complete\")\n",
    "                highlight_num += 1\n",
    "                if split_segments:\n",
    "                    out.release()\n",
    "                    out = cv.VideoWriter(f\"{Path(input_video_path).stem}_highlight_{highlight_num}.mp4\", fourcc, fps, (original_width, original_height))\n",
    "            else:\n",
    "                out.write(frame)\n",
    "\n",
    "    # Release everything when job is finished\n",
    "    cap.release()\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# snip snip!!\n",
    "\n",
    "[Website](https://yt5s.biz/watch?v=ACR3RUiV6Rw) for free youtube audio download\n",
    "\n",
    "[Clideo](https://clideo.com/editor/add-audio-to-video) for adding audio to highlight reel (TODO do this in python so no watermarks :p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose your file!\n",
    "input_video_path = \"C0013.MP4\"\n",
    "cropped_video_path = \"output_cropped.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, w, h = 750, 280, 250, 150  # Specify the x, y, width, and height of basket\n",
    "# TODO bound basket automatically with polygon detection?\n",
    "crop_video(input_video_path, cropped_video_path, x, y, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 2250/19512 [00:02<00:21, 814.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basket made at: 0m43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 2951/19512 [00:03<00:21, 785.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basket made at: 0m56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3533/19512 [00:04<00:19, 808.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basket made at: 1m9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 5439/19512 [00:06<00:17, 825.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basket made at: 1m46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 8576/19512 [00:10<00:15, 714.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basket made at: 2m50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 14457/19512 [00:17<00:06, 787.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basket made at: 4m47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 14940/19512 [00:18<00:05, 764.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basket made at: 4m56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 15637/19512 [00:19<00:05, 746.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basket made at: 5m11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 16368/19512 [00:20<00:04, 765.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basket made at: 5m25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 17272/19512 [00:21<00:02, 794.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basket made at: 5m43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 18638/19512 [00:23<00:01, 694.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basket made at: 6m11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19512/19512 [00:24<00:00, 782.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found  11  scored baskets.\n"
     ]
    }
   ],
   "source": [
    "score_framestamps = get_score_framestamps(cropped_video_path, (115,160), (105, 115))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 2277/19512 [00:40<08:00, 35.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highlight 0 complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 2928/19512 [01:02<07:45, 35.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highlight 1 complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3558/19512 [01:23<08:16, 32.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highlight 2 complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 5435/19512 [02:02<06:52, 34.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highlight 3 complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 8618/19512 [03:01<04:35, 39.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highlight 4 complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 14438/19512 [12:40<02:31, 33.40it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highlight 5 complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 14908/19512 [12:59<01:54, 40.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highlight 6 complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 15652/19512 [13:21<01:49, 35.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highlight 7 complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 16366/19512 [13:41<01:31, 34.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highlight 8 complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 17263/19512 [14:06<00:55, 40.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highlight 9 complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 18655/19512 [14:37<00:40, 21.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highlight 10 complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "segment_video(input_video_path, score_framestamps, before_score_seconds=5, after_score_seconds=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
